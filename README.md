# Practica Bigdata-architecture

### Parte 1.
. Utilizar una herramienta de diagrama como google Draw o DIA para diseñar y especificar el flujo de datos y herramientas utilizadas.

### Parte 2.
. Crear un scraper en google Collaboratory a partir de un API o de un crawler con Scrapy, que descargue los datos a un archivo de formato estructurado.
Parte 2 pincha [aqui](https://drive.google.com/open?id=1RZ4IYhaI4GkF_L3R6YASdIiLTIv_8ixL)

### Parte 3.
. Utilizar un proveedor de Cloud para montar un cluster de al menos 3 contenedores configurados correctamente o hacerlo en el cluster local

### Parte 4.
Subir los archivos extraídos durante la parte 2 al cluster de Hadoop e insertarlos en el HDFS.
Indicar pasos necesarios para realizar esto, dependiendo de la opción elegida en el Sprint 3
Realizar la tarea de procesamiento de datos sobre los datos extraídos utilizando WordCount.

### Parte 5
Utilizar HIVE/Elastic/Kafka/Mongo para insertar los datos extraídos durante el Sprint 2 y realizar operaciones con los mismos.
Indicar los pasos y las decisiones de diseño respecto a cómo organizar los datos.


